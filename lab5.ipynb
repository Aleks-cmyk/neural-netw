{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPqJH17IpdER4hRli4hD65u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aleks-cmyk/neural-netw/blob/master/lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лабораторна робота 5\n",
        "\n",
        "студентки КН-31\n",
        "\n",
        "Мензатюк Олександри"
      ],
      "metadata": {
        "id": "fb7U50HAINVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання\n",
        "На основі документу вирішити завдання класифікації зображень їжі для 3 класів з набору даних food101.\n",
        "\n",
        "\n",
        "Індекси класів визначити індивідуально за залежностями: i1 = n - 1 = 4, i2 = n + 29 = 34, i3 = n + 59 = 64 (де і1, і2, і3 - індекс класу (починаючи з 0) у відсортованому за алфавітом наборі даних, n = 5 - номер за списком групи."
      ],
      "metadata": {
        "id": "pLK1pAUfJbdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import os\n",
        "import zipfile\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import shutil\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "63xgsFNqKYBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWD6wg-qIMlM",
        "outputId": "f451eeac-a52b-4596-b958-b68fed8a784b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-21 07:12:51--  https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.128, 74.125.135.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1625420029 (1.5G) [application/zip]\n",
            "Saving to: ‘101_food_classes_10_percent.zip.3’\n",
            "\n",
            "101_food_classes_10 100%[===================>]   1.51G   239MB/s    in 7.6s    \n",
            "\n",
            "2022-05-21 07:12:59 (203 MB/s) - ‘101_food_classes_10_percent.zip.3’ saved [1625420029/1625420029]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"101_food_classes_10_percent.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls 101_food_classes_10_percent/train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOJ_HqozKRJa",
        "outputId": "603dfeba-3e7f-4396-cd9a-452d5780351b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple_pie\t    eggs_benedict\t     onion_rings\n",
            "baby_back_ribs\t    escargots\t\t     oysters\n",
            "baklava\t\t    falafel\t\t     pad_thai\n",
            "beef_carpaccio\t    filet_mignon\t     paella\n",
            "beef_tartare\t    fish_and_chips\t     pancakes\n",
            "beet_salad\t    foie_gras\t\t     panna_cotta\n",
            "beignets\t    french_fries\t     peking_duck\n",
            "bibimbap\t    french_onion_soup\t     pho\n",
            "bread_pudding\t    french_toast\t     pizza\n",
            "breakfast_burrito   fried_calamari\t     pork_chop\n",
            "bruschetta\t    fried_rice\t\t     poutine\n",
            "caesar_salad\t    frozen_yogurt\t     prime_rib\n",
            "cannoli\t\t    garlic_bread\t     pulled_pork_sandwich\n",
            "caprese_salad\t    gnocchi\t\t     ramen\n",
            "carrot_cake\t    greek_salad\t\t     ravioli\n",
            "ceviche\t\t    grilled_cheese_sandwich  red_velvet_cake\n",
            "cheesecake\t    grilled_salmon\t     risotto\n",
            "cheese_plate\t    guacamole\t\t     samosa\n",
            "chicken_curry\t    gyoza\t\t     sashimi\n",
            "chicken_quesadilla  hamburger\t\t     scallops\n",
            "chicken_wings\t    hot_and_sour_soup\t     seaweed_salad\n",
            "chocolate_cake\t    hot_dog\t\t     shrimp_and_grits\n",
            "chocolate_mousse    huevos_rancheros\t     spaghetti_bolognese\n",
            "churros\t\t    hummus\t\t     spaghetti_carbonara\n",
            "clam_chowder\t    ice_cream\t\t     spring_rolls\n",
            "club_sandwich\t    lasagna\t\t     steak\n",
            "crab_cakes\t    lobster_bisque\t     strawberry_shortcake\n",
            "creme_brulee\t    lobster_roll_sandwich    sushi\n",
            "croque_madame\t    macaroni_and_cheese      tacos\n",
            "cup_cakes\t    macarons\t\t     takoyaki\n",
            "deviled_eggs\t    miso_soup\t\t     tiramisu\n",
            "donuts\t\t    mussels\t\t     tuna_tartare\n",
            "dumplings\t    nachos\t\t     waffles\n",
            "edamame\t\t    omelette\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"101_food_classes_10_percent/train/\"\n",
        "test_dir = \"101_food_classes_10_percent/test/\""
      ],
      "metadata": {
        "id": "DtJWOPcGLNBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path(train_dir)\n",
        "all_class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "\n",
        "indexes = [4, 34, 64]\n",
        "\n",
        "class_names = np.array([])\n",
        "\n",
        "for i, name in enumerate(all_class_names):\n",
        "  if i in indexes:\n",
        "    print(i, name)\n",
        "    class_names = np.append(class_names, name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Oqo_DHXMAzU",
        "outputId": "8934b0dd-6791-4194-c002-055cc888c61f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 beef_tartare\n",
            "34 eggs_benedict\n",
            "64 miso_soup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir beeftartare_eggsbenedict_misosoup\n",
        "\n",
        "!mkdir beeftartare_eggsbenedict_misosoup/train\n",
        "!mkdir beeftartare_eggsbenedict_misosoup/test"
      ],
      "metadata": {
        "id": "UBaULt9JMRVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sources = [\n",
        "  'beef_tartare',\n",
        "  'eggs_benedict',\n",
        "  'miso_soup'\n",
        "]\n",
        "\n",
        "for source in sources:\n",
        "  source_dir = train_dir + source\n",
        "  destination_dir = 'beeftartare_eggsbenedict_misosoup/train/' + source\n",
        "  shutil.copytree(source_dir, destination_dir)\n",
        "\n",
        "for source in sources:\n",
        "  source_dir = test_dir + source\n",
        "  destination_dir = 'beeftartare_eggsbenedict_misosoup/test/' + source\n",
        "  shutil.copytree(source_dir, destination_dir)"
      ],
      "metadata": {
        "id": "85apDCTFMvd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"beeftartare_eggsbenedict_misosoup/train/\"\n",
        "test_dir = \"beeftartare_eggsbenedict_misosoup/test/\""
      ],
      "metadata": {
        "id": "Of5vgEK-M83e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4zbW1-DNQ_9",
        "outputId": "cd8f0d9b-2b6b-4531-f320-f412ebac4d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['beef_tartare' 'eggs_benedict' 'miso_soup']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(test_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode='categorical')\n",
        "\n",
        "test_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxmr5f1gNWB-",
        "outputId": "044e417b-ec88-4325-b3aa-acb5d343ec94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 images belonging to 3 classes.\n",
            "Found 225 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
        "                                             rotation_range=20, \n",
        "                                             width_shift_range=0.2,\n",
        "                                             height_shift_range=0.2,\n",
        "                                             zoom_range=0.2,\n",
        "                                             horizontal_flip=True)\n",
        "\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(test_dir,\n",
        "                                                                  target_size=(224, 224),\n",
        "                                                                  batch_size=32,\n",
        "                                                                  class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lmpAvAQYo3g",
        "outputId": "81033dcf-da72-4de0-c5a5-99579b0a43ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cnn_model = Sequential([\n",
        "  Conv2D(32, 3, activation='relu', input_shape=(224, 224, 3)),\n",
        "  MaxPool2D(),\n",
        "  Dense(128, activation='relu'),\n",
        "  Conv2D(64, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "result_cnn_model = cnn_model.fit(train_data_augmented,\n",
        "                          epochs=50,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uY3lwaQYsoM",
        "outputId": "9a7c189d-29c0-4367-d407-5a0d6fffe253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 13s 513ms/step - loss: 1.5333 - accuracy: 0.3947 - val_loss: 0.9649 - val_accuracy: 0.4844\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 12s 483ms/step - loss: 0.9743 - accuracy: 0.4947 - val_loss: 0.8498 - val_accuracy: 0.6222\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 11s 477ms/step - loss: 0.9604 - accuracy: 0.4827 - val_loss: 0.8814 - val_accuracy: 0.6133\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 11s 476ms/step - loss: 0.9422 - accuracy: 0.5480 - val_loss: 0.8143 - val_accuracy: 0.6044\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 12s 480ms/step - loss: 0.8466 - accuracy: 0.6107 - val_loss: 0.7231 - val_accuracy: 0.6933\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 11s 477ms/step - loss: 0.7969 - accuracy: 0.6413 - val_loss: 0.8312 - val_accuracy: 0.6533\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 12s 482ms/step - loss: 0.8491 - accuracy: 0.6133 - val_loss: 0.7512 - val_accuracy: 0.6756\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 11s 476ms/step - loss: 0.8367 - accuracy: 0.6027 - val_loss: 0.8756 - val_accuracy: 0.6000\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 11s 475ms/step - loss: 0.8002 - accuracy: 0.6480 - val_loss: 0.6924 - val_accuracy: 0.6889\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 12s 479ms/step - loss: 0.7670 - accuracy: 0.6547 - val_loss: 0.7426 - val_accuracy: 0.6800\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 11s 477ms/step - loss: 0.7333 - accuracy: 0.6827 - val_loss: 0.7778 - val_accuracy: 0.6844\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 11s 472ms/step - loss: 0.7423 - accuracy: 0.6760 - val_loss: 0.7627 - val_accuracy: 0.6844\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 11s 471ms/step - loss: 0.7718 - accuracy: 0.6600 - val_loss: 0.7311 - val_accuracy: 0.6978\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 11s 471ms/step - loss: 0.7616 - accuracy: 0.6747 - val_loss: 0.7138 - val_accuracy: 0.6933\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 11s 470ms/step - loss: 0.7552 - accuracy: 0.6627 - val_loss: 0.7527 - val_accuracy: 0.6800\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 11s 474ms/step - loss: 0.7813 - accuracy: 0.6360 - val_loss: 0.8526 - val_accuracy: 0.6400\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 11s 472ms/step - loss: 0.7568 - accuracy: 0.6547 - val_loss: 0.7076 - val_accuracy: 0.6978\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 11s 472ms/step - loss: 0.6907 - accuracy: 0.7093 - val_loss: 0.7629 - val_accuracy: 0.6889\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 11s 472ms/step - loss: 0.7397 - accuracy: 0.6587 - val_loss: 0.7365 - val_accuracy: 0.7200\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 11s 474ms/step - loss: 0.6993 - accuracy: 0.6760 - val_loss: 0.8242 - val_accuracy: 0.6978\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 11s 476ms/step - loss: 0.7098 - accuracy: 0.7000 - val_loss: 0.7739 - val_accuracy: 0.7156\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 11s 474ms/step - loss: 0.6792 - accuracy: 0.7107 - val_loss: 0.7655 - val_accuracy: 0.7111\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 11s 472ms/step - loss: 0.7234 - accuracy: 0.6867 - val_loss: 0.7514 - val_accuracy: 0.6756\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 11s 473ms/step - loss: 0.6945 - accuracy: 0.6827 - val_loss: 0.7837 - val_accuracy: 0.6800\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 12s 484ms/step - loss: 0.6883 - accuracy: 0.6987 - val_loss: 0.7357 - val_accuracy: 0.7022\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 11s 476ms/step - loss: 0.7044 - accuracy: 0.6880 - val_loss: 0.7796 - val_accuracy: 0.6978\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 12s 480ms/step - loss: 0.6978 - accuracy: 0.6840 - val_loss: 0.6728 - val_accuracy: 0.7022\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 12s 480ms/step - loss: 0.6949 - accuracy: 0.6773 - val_loss: 0.7760 - val_accuracy: 0.6800\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 12s 479ms/step - loss: 0.6958 - accuracy: 0.7133 - val_loss: 0.7746 - val_accuracy: 0.6978\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 12s 491ms/step - loss: 0.6490 - accuracy: 0.7120 - val_loss: 0.6830 - val_accuracy: 0.7422\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 12s 479ms/step - loss: 0.6346 - accuracy: 0.7240 - val_loss: 0.6661 - val_accuracy: 0.7422\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 12s 492ms/step - loss: 0.6421 - accuracy: 0.7160 - val_loss: 0.7271 - val_accuracy: 0.7378\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 11s 476ms/step - loss: 0.6582 - accuracy: 0.7080 - val_loss: 0.8639 - val_accuracy: 0.6978\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 12s 478ms/step - loss: 0.6864 - accuracy: 0.7067 - val_loss: 0.6595 - val_accuracy: 0.7689\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 11s 474ms/step - loss: 0.6137 - accuracy: 0.7307 - val_loss: 0.6059 - val_accuracy: 0.7733\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 11s 473ms/step - loss: 0.6597 - accuracy: 0.7027 - val_loss: 0.7688 - val_accuracy: 0.7289\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 11s 476ms/step - loss: 0.6788 - accuracy: 0.6920 - val_loss: 0.6953 - val_accuracy: 0.7289\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 12s 482ms/step - loss: 0.5834 - accuracy: 0.7707 - val_loss: 0.7030 - val_accuracy: 0.7289\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 11s 474ms/step - loss: 0.6435 - accuracy: 0.7240 - val_loss: 0.7724 - val_accuracy: 0.7067\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 11s 476ms/step - loss: 0.6097 - accuracy: 0.7400 - val_loss: 0.5764 - val_accuracy: 0.7911\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 11s 474ms/step - loss: 0.5931 - accuracy: 0.7467 - val_loss: 0.7804 - val_accuracy: 0.7156\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 11s 473ms/step - loss: 0.6217 - accuracy: 0.7280 - val_loss: 0.7178 - val_accuracy: 0.7333\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 11s 475ms/step - loss: 0.6306 - accuracy: 0.6960 - val_loss: 0.6692 - val_accuracy: 0.7778\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 11s 474ms/step - loss: 0.5739 - accuracy: 0.7560 - val_loss: 0.5444 - val_accuracy: 0.7733\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 11s 478ms/step - loss: 0.5707 - accuracy: 0.7587 - val_loss: 0.7607 - val_accuracy: 0.7200\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 12s 479ms/step - loss: 0.5704 - accuracy: 0.7427 - val_loss: 0.7394 - val_accuracy: 0.7244\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 11s 470ms/step - loss: 0.6115 - accuracy: 0.7400 - val_loss: 0.5694 - val_accuracy: 0.7556\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 11s 471ms/step - loss: 0.5872 - accuracy: 0.7480 - val_loss: 0.7255 - val_accuracy: 0.7200\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 11s 473ms/step - loss: 0.6153 - accuracy: 0.7467 - val_loss: 0.5959 - val_accuracy: 0.7822\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 11s 473ms/step - loss: 0.5858 - accuracy: 0.7627 - val_loss: 0.7492 - val_accuracy: 0.7156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Висновок\n",
        "В ході виконання лабораторної роботи було створено нейромережу для розв'язання задачі класифікації зображень їжі. Спочатку було розділено зображення у відношенні 1:3 - (тренувальна вибірка:тестова вибірка). У такому варіанті найкращою точністю передбачень було значення 0.65. після цього було розділено всі зображення у відношенні 3:1, тобто тепер стало набагато більше навчальних прикладів. Після цього, точність передбачення зросла до 7.1"
      ],
      "metadata": {
        "id": "mTn0UGEhIVQY"
      }
    }
  ]
}